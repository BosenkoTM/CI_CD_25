# Лабораторная работа 2.1. Создание Dockerfile и сборка образа для аналитических приложений

## Цель работы
Научиться разрабатывать воспроизводимые аналитические инструменты. Студенту необходимо пройти полный цикл: от написания Python-скрипта для обработки бизнес-данных до его упаковки в Docker-образ и запуска в изолированной среде.

## Необходимые инструменты и технологии
Для выполнения работы потребуются:
*   **Платформа.** Виртуальная машина из образа `dev_kub_student.ova` (Ubuntu-based).  
    *   [Ссылка для скачивания образа](https://envlab.ru/mod/folder/view.php?id=1078)
*   **Языки и библиотеки:** Python 3.9+ (Pandas, NumPy, Matplotlib, Flask, FastAPI), SQL (опционально).
*   **Инструменты:** Docker CE, текстовый редактор (VS Code/Nano), Git.
*   **Репозиторий:** GitHub или GitVerse.

## Задачи
-  **Аналитическая часть.** Написать скрипт/приложение, которое генерирует или загружает набор данных (согласно вашей тематике) и производит их анализ (расчет метрик, фильтрация, построение графика).
-  **Техническая часть.** Создать оптимальный `Dockerfile` для этого приложения.
-  **Сборка и запуск.** Собрать образ, запустить контейнер и продемонстрировать вывод результатов (в консоль, в файл или через API).
-  **Отчет.** Загрузить код и отчет в репозиторий.

## Критерии оценки (Всего 10 баллов)
| Критерий | Баллы | Описание |
| :--- | :---: | :--- |
| **Аналитический скрипт** | 2 | Скрипт выполняет бизнес-задачу (генерирует данные, считает метрики), код чистый, используется Pandas/NumPy. |
| **Dockerfile** | 3 | Инструкции (`FROM`, `COPY`, `RUN`) корректны. Используется `.dockerignore`. Образ оптимизирован (нет лишних файлов). |
| **Сборка образа** | 3 | Сборка проходит без ошибок. Зависимости (`requirements.txt`) установлены верно. |
| **Результат работы** | 2 | Контейнер запускается, выдает ожидаемый результат (JSON, текст или файл). |

---

## Тематики данных (Ваши данные)

В каждом варианте вам необходимо работать с определенной предметной областью. Вы можете найти реальный CSV-файл в интернете или сгенерировать синтетические данные (через библиотеку `Faker` или `random`) внутри скрипта.

| № Темы | Предметная область | Примерные поля данных |
| :---: | :--- | :--- |
| **1** | **E-commerce Sales** | ID заказа, дата, сумма, категория товара, статус возврата. |
| **2** | **HR & Retention** | Сотрудник, возраст, стаж, зарплата, уровень удовлетворенности, уволился (да/нет). |
| **3** | **Inventory / Склад** | SKU товара, остаток на складе, скорость продаж, срок годности, поставщик. |
| **4** | **Website Traffic** | IP, страница входа, время на сайте, устройство, конверсия (цель достигнута). |
| **5** | **Real Estate** | Район, площадь, цена, этаж, год постройки, тип материала. |
| **6** | **Credit Risk** | ID клиента, кредитный рейтинг, доход, сумма долга, наличие просрочек. |
| **7** | **Social Media** | ID поста, количество лайков, репостов, длина текста, тональность (positive/negative). |
| **8** | **Supply Chain** | Маршрут, время в пути, стоимость перевозки, вес груза, тип транспорта. |
| **9** | **Customer Support** | ID тикета, время реакции, время решения, оценка пользователя, категория проблемы. |
| **10** | **Stock Market** | Тикер, дата, цена открытия, цена закрытия, объем торгов. |

*Примечание.* Если ваш вариант превышает число тем, используйте формулу: `(Вариант - 1) % 10 + 1`. Например, 11 вариант = тема 1, 25 вариант = тема 5.

---

## Ход работы (Пример для Варианта 25)
*Тема: Real Estate (Недвижимость). Задача: Flask API.*

### Этап 1. Написание аналитического сервиса
Создадим структуру проекта:
```bash
mkdir real-estate-analytics
cd real-estate-analytics
```

Файл `app.py`. Сервис генерирует данные о квартирах и отдает среднюю цену за кв. метр:
```python
from flask import Flask, jsonify
import pandas as pd
import numpy as np
import random

app = Flask(__name__)

def generate_data():
    # Генерируем синтетические данные
    data = {
        'district': [random.choice(['Center', 'North', 'South']) for _ in range(100)],
        'price': np.random.uniform(5000000, 20000000, 100),
        'area': np.random.uniform(30, 120, 100)
    }
    df = pd.DataFrame(data)
    return df

@app.route('/report')
def get_report():
    df = generate_data()
    # Аналитика: расчет цены за квадратный метр
    df['price_per_sqm'] = df['price'] / df['area']
    
    # Группировка по районам
    report = df.groupby('district')['price_per_sqm'].mean().round(2).to_dict()
    
    return jsonify({
        "status": "success",
        "metric": "Average Price per Sqm by District",
        "data": report
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

Файл `requirements.txt`:
```text
Flask
pandas
numpy
```

### Этап 2. Создание Dockerfile
Файл `Dockerfile`:
```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Копируем зависимости отдельно для кэширования слоев
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Копируем код
COPY app.py .

EXPOSE 5000

CMD ["python", "app.py"]
```

### Этап 3. Сборка и проверка
```bash
docker build -t estate-service:v1 .
docker run -d -p 5000:5000 estate-service:v1
# Проверка
curl http://localhost:5000/report
```

---

## Индивидуальные задания

Выберите вариант. Ваше задание состоит из **Темы данных** (см. таблицу выше) и **Технического задания** (таблица ниже).

| Вариант | Стек технологий | Задание (Аналитика + Docker) |
| :---: | :--- | :--- |
| **1** | **Python + Pandas (CLI)** | Скрипт генерирует DataFrame, рассчитывает основные статистики (`describe()`), сохраняет результат в `.txt` файл и выводит содержимое файла в консоль (`cat`). |
| **2** | **Python + Matplotlib** | Скрипт генерирует временной ряд (даты и значения), строит линейный график и сохраняет его как `chart.png`. *Задача Docker:* обеспечить доступ к файлу после остановки контейнера (Volume не обязателен, достаточно скопировать через `docker cp` для отчета). |
| **3** | **Node.js API** | Сервис на Express.js. Генерирует массив JSON-объектов (по теме) и имеет эндпоинт `/filter?min=X`, возвращающий записи, где значение метрики > X. |
| **4** | **Python + NumPy** | Скрипт создает две матрицы (например, цены и количества), выполняет их перемножение для расчета общей выручки и выводит итоговую сумму. |
| **5** | **Flask Web** | Веб-приложение с HTML-шаблоном. При заходе на главную страницу отображает таблицу с данными (Pandas to HTML) по вашей тематике. |
| **6** | **Go (Golang)** | Консольная утилита. Читает (или генерирует) CSV-строки, парсит их и считает среднее арифметическое по выбранной колонке. Сборка через Multi-stage build приветствуется. |
| **7** | **Python + Scikit-learn** | Скрипт генерирует данные для регрессии (X и y), обучает простую модель `LinearRegression` и выводит коэффициенты модели (влияние факторов). |
| **8** | **Python + Requests** | Скрипт скачивает реальный JSON (например, курсы валют или погоду), преобразует его в Pandas DataFrame, находит максимум/минимум и выводит в консоль. |
| **9** | **R Script** | Скрипт на языке R. Создает data.frame, проводит группировку (aggregate) и выводит сводную таблицу в консоль. |
| **10** | **Apache (Static Report)** | Сгенерировать HTML-отчет заранее (можно вручную или скриптом). Создать образ на базе `httpd`, куда "зашивается" этот отчет как `index.html`. |
| **11** | **Python Cron Job** | Скрипт работает в бесконечном цикле. Каждые 10 секунд генерирует новую запись данных и пишет её в лог контейнера (stdout) с меткой времени. |
| **12** | **Python + SQLite** | Скрипт создает БД SQLite, таблицу по теме, вставляет 50 строк синтетических данных и выполняет SQL-запрос с агрегацией (`GROUP BY`). |
| **13** | **Streamlit** | Создать Dashboard на Streamlit. Отобразить заголовок и один график (bar chart) по вашим данным. Правильно настроить CMD и EXPOSE. |
| **14** | **Java (Maven/Gradle)** | Простое приложение, которое рассчитывает статистическое отклонение для массива чисел (Java Math). Сборка Jar-файла. |
| **15** | **Python + Faker** | Использовать библиотеку `Faker` для генерации "грязных" данных (с пропусками). Скрипт должен очистить данные (fillna/dropna) и вывести результат. |
| **16** | **Node.js (Analytics)** | Использовать библиотеку типа `simple-statistics` или нативный JS для расчета медианы и моды массива данных. |
| **17** | **Jupyter Notebook** | Собрать образ с предустановленным Jupyter и библиотеками (Pandas, Seaborn). CMD должен запускать Jupyter Lab без токена. |
| **18** | **Python + Seaborn** | Скрипт строит тепловую карту (heatmap) корреляции признаков, сохраняет её в файл. |
| **19** | **Python CLI Arguments** | Скрипт принимает аргументы при запуске (через `sys.argv` или `argparse`), например `--count 100`, генерирует указанное число строк и сохраняет в CSV. |
| **20** | **PostgreSQL Client** | Образ на базе Python. Скрипт ждет (wait-for-it) и пытается подключиться к несуществующей БД, обрабатывает ошибку подключения (try-except) и пишет лог "Database unavailable, switching to local mode". |
| **21** | **Python + Plotly** | Скрипт генерирует HTML-файл с интерактивным графиком Plotly. Задача — забрать этот HTML из контейнера. |
| **22** | **FastAPI (Scoring)** | Сервис для скоринга. Принимает JSON (POST запрос) с параметрами объекта (например, "доход"), применяет простую логику (if доход > 50000: score=10) и возвращает результат. Использовать `uvicorn`. |
| **23** | **Ruby Analytics** | Скрипт на Ruby. Читает массив хэшей (данные), фильтрует их по условию и считает количество элементов. |
| **24** | **Nginx (Custom Config)** | Настроить Nginx так, чтобы он отдавал статический JSON-файл с данными по адресу `/api/data`. JSON файл должен быть скопирован внутрь образа. |
| **25** | **Flask + Jinja2** | Веб-приложение. Генерирует данные, передает их в шаблон Jinja2, который рендерит HTML-страницу со списком (ul/li). |

---

## Требования к отчетности

Все работы выгружаются в репозиторий на **GitHub** или **GitVerse**.

### Структура папки `lab_02.1`:
-  **app/** (или src/). Папка с исходным кодом аналитического приложения.
-  **Dockerfile**. Файл инструкций сборки.
-  **requirements.txt** (или аналоги). Файл зависимостей.
-  **REPORT.md**. Отчет.

### Содержание отчета (`REPORT.md`):
-  **Титульный лист** (ФИО, группа, вариант, тема данных).
-  **Описание задачи.** Какую бизнес-метрику вы считаете, какие данные используете.
-  **Листинг кода:**
    *   Ключевые фрагменты скрипта аналитики (генерация, расчет).
    *   Полный текст Dockerfile с пояснениями.
-  **Скриншоты:**
    *   Процесс сборки (`docker build`).
    *   Запуск контейнера (`docker run`).
    *   Результат (вывод консоли, ответ API, созданный файл).
-  **Ответы на контрольные вопросы.**

---

## Контрольные вопросы
1.  Для чего нужна инструкция `WORKDIR` и что произойдет, если её не указать?
2.  В чем разница между `COPY . .` и копированием отдельных файлов? Как это влияет на кэширование слоев?
3.  Зачем указывать `EXPOSE` в Dockerfile, если порт все равно нужно пробрасывать при запуске (`-p`)?
4.  Как уменьшить размер финального образа для Python-приложения? (Назовите 2-3 способа).
5.  Как передать файл (например, отчет) из контейнера на хост-машину, если контейнер уже завершил работу?
```