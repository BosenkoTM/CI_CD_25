# Лабораторная работа №3.1. Развертывание аналитических сервисов в Kubernetes


## Цель работы
Освоить процесс оркестрации контейнеров. Научиться разворачивать связки сервисов (аналитическое приложение + база данных/интерфейс) в кластере Kubernetes, управлять их масштабированием (Deployment) и сетевой доступностью (Service).

## Необходимые инструменты и технологии
Для выполнения работы потребуются:
*   **Платформа:** Виртуальная машина из образа `dev_kub_student.ova` (Ubuntu-based + MicroK8s/Docker).
    *   [Ссылка для скачивания образа](https://envlab.ru/mod/folder/view.php?id=1078)
*   **Инструменты:** `kubectl` (интерфейс командной строки Kubernetes), текстовый редактор.
*   **Образы:** Будем использовать официальные образы с Docker Hub (Postgres, Metabase, Jupyter и др.).
*   **Репозиторий:** GitHub или GitVerse.

> **Важно.** Если в вашей ВМ используется MicroK8s, команды могут выглядеть как `microk8s kubectl ...`. Рекомендуется сделать алиас: `alias kubectl='microk8s kubectl'`.

## Задачи
-  Создать манифест **Deployment** для основного аналитического приложения (согласно варианту).
-  Создать манифест **Deployment** для вспомогательного сервиса (БД, кэш, GUI), если требуется по заданию.
-  Создать манифесты **Service** для открытия доступа к приложениям.
-  Запустить конфигурации в кластере и проверить взаимодействие компонентов.
-  Оформить отчет в репозитории.

## Критерии оценки (Всего 20 баллов)
| Критерий | Баллы | Описание |
| :--- | :---: | :--- |
| **Deployment Manifests** | 6 | YAML-файлы корректны, синтаксис валиден, указаны правильные образы, порты и переменные окружения. |
| **Service Manifests** | 6 | Сервисы созданы, корректно ссылаются на Pods (selector), выбраны верные порты. |
| **Работоспособность** | 4 | Поды находятся в статусе `Running`, приложение доступно из браузера или консоли (curl). |
| **Индивидуальное задание** | 4 | Реализована связка технологий, указанная в варианте (Бизнес-контекст соблюден). |

---

## Ход работы (Пример. Развертывание BI-системы Metabase)

В качестве примера развернем **Metabase** — популярный open-source инструмент для бизнес-аналитики и визуализации данных.

### Шаг 1. Проверка состояния кластера
Убедитесь, что кластер запущен и готов к работе:
```bash
kubectl get nodes
kubectl get pods -A
```

### Шаг 2. Создание Deployment
Создайте файл `metabase-deployment.yaml`. Мы опишем приложение, которое будет запущено в одном экземпляре.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: metabase-app
  labels:
    app: metabase
spec:
  replicas: 1
  selector:
    matchLabels:
      app: metabase
  template:
    metadata:
      labels:
        app: metabase
    spec:
      containers:
      - name: metabase
        image: metabase/metabase:latest
        ports:
        - containerPort: 3000
        resources:
          limits:
            memory: "1024Mi"
            cpu: "500m"
```

Примените конфигурацию:
```bash
kubectl apply -f metabase-deployment.yaml
```

Проверьте, что под запускается (статус может быть `ContainerCreating`, затем `Running`):
```bash
kubectl get pods
```

### Шаг 3. Создание Service
Чтобы зайти в веб-интерфейс Metabase, нужно открыть порт. Создайте файл `metabase-service.yaml`.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: metabase-service
spec:
  selector:
    app: metabase
  # Используем NodePort для доступа к ВМ по порту, если нет внешнего балансировщика
  type: NodePort 
  ports:
    - port: 80         # Порт внутри кластера
      targetPort: 3000 # Порт контейнера
      nodePort: 30080  # Порт, по которому мы пойдем в браузере (30000-32767)
```

Примените сервис:
```bash
kubectl apply -f metabase-service.yaml
```

### Шаг 4. Проверка доступности
1.  Узнайте IP-адрес вашей виртуальной машины (команда `ip a` или `ifconfig`).
2.  Откройте браузер на хост-машине и перейдите по адресу: `http://<IP-ВАШЕЙ-ВМ>:30080`.
3.  Вы должны увидеть стартовую страницу настройки Metabase.

### Шаг 5. Очистка ресурсов (после завершения работы)
```bash
kubectl delete -f metabase-service.yaml
kubectl delete -f metabase-deployment.yaml
```

---

## Индивидуальные задания

Вам необходимо выбрать вариант и развернуть указанную связку сервисов.
**Важно.** Для связывания сервисов (например, App подключается к DB) используйте **имя сервиса** базы данных как хост (например, `db-service`).

| Вариант | Основной сервис (App) | Вспомогательный сервис (DB/Tool) | Задача |
| :---: | :--- | :--- | :--- |
| **1** | **Jupyter Notebook** | **Постоянное хранилище** (Volume) | Развернуть `jupyter/base-notebook`. Обеспечить сохранение ноутбуков при перезапуске пода (использовать PVC или hostPath). |
| **2** | **PostgreSQL** | **Adminer** (Web GUI) | Развернуть БД Postgres и веб-интерфейс Adminer. Настроить Adminer на подключение к сервису Postgres. Открыть доступ к Adminer в браузере. |
| **3** | **MySQL** | **phpMyAdmin** | Классическая связка для аналитики данных интернет-магазинов. Развернуть MySQL (указать переменные пароля) и phpMyAdmin. |
| **4** | **Redis** | **Redis Commander** | Развернуть Redis для кэширования и Redis Commander для просмотра ключей в браузере. |
| **5** | **ClickHouse Server** | **Tabix** (Web GUI) | Развернуть аналитическую БД ClickHouse и интерфейс Tabix (или использовать встроенный HTTP интерфейс) для выполнения SQL-запросов. |
| **6** | **Metabase** | **PostgreSQL** | Развернуть Metabase и подключить его к отдельному контейнеру PostgreSQL (хранилище метаданных самого Metabase). |
| **7** | **Grafana** | **Prometheus** | Развернуть систему мониторинга. Grafana должна быть доступна через браузер (login: admin/admin). |
| **8** | **Python ML API** | **Redis** | Создать свой образ (или взять простой python-app), который при запросе увеличивает счетчик в Redis. Развернуть оба сервиса. |
| **9** | **Mongo DB** | **Mongo Express** | Развернуть NoSQL базу данных MongoDB и веб-админку Mongo Express. Настроить переменные окружения для авторизации. |
| **10** | **Elasticsearch** | **Kibana** | (Требует много ОЗУ). Развернуть Elasticsearch (single-node) и Kibana для визуализации логов/данных. |
| **11** | **MinIO** | **MinIO Client (Job)** | Развернуть S3-хранилище MinIO. Открыть доступ к консоли. Опционально: запустить Job, создающий бакет. |
| **12** | **Apache Superset** | **PostgreSQL** | (Упрощенно). Попытаться развернуть Superset (или облегченную версию) с подключением к БД. |
| **13** | **Ghost** | **MySQL** | Платформа для корпоративного блога/отчетности. Развернуть Ghost CMS с подключением к MySQL. |
| **14** | **Wordpress** | **MariaDB** | Сайт для публикации аналитических отчетов. Развернуть Wordpress + MariaDB. |
| **15** | **FastAPI App** | **PostgreSQL** | Развернуть Python-приложение (можно взять из Лаб 2) и БД Postgres. Настроить ENV переменные в Deployment приложения для связи с БД. |
| **16** | **RabbitMQ** | **Management Plugin** | Развернуть брокер сообщений. Обязательно открыть порт 15672 для доступа к веб-панели управления очередями. |
| **17** | **Nginx (Custom)** | **Static HTML** | Развернуть Nginx, который отдает аналитический отчет (ConfigMap с HTML-файлом смонтировать в `/usr/share/nginx/html`). |
| **18** | **InfluxDB** | **Chronograf** | Развернуть БД временных рядов InfluxDB и интерфейс Chronograf для визуализации метрик. |
| **19** | **Odoo** | **PostgreSQL** | Развернуть ERP-систему Odoo. Проверить доступность веб-интерфейса и связь с БД. |
| **20** | **Spark Master** | **Spark Worker** | Развернуть кластер Apache Spark (1 master, 1 worker). Открыть веб-интерфейс Master-ноды (обычно порт 8080). |
| **21** | **Registry** | **Registry UI** | Развернуть локальный Docker Registry и простой веб-интерфейс для просмотра образов. |
| **22** | **MLflow** | **PostgreSQL** | Развернуть MLflow Server (Tracking server) с бэкендом в Postgres для хранения метрик моделей. |
| **23** | **Keycloak** | **PostgreSQL** | Развернуть систему управления доступом (Identity Provider), часто используемую в корпоративной аналитике. |
| **24** | **Node.js Analytics** | **MongoDB** | Приложение на Node.js, собирающее метрики, и Mongo для их хранения. Проверить запись данных. |
| **25** | **Redash** | **Redis/Postgres** | (Или упрощенный аналог). Развернуть систему визуализации Redash (требует Redis и PG). Проверить запуск веб-интерфейса. |

---

## Требования к отчетности

Все работы выгружаются в репозиторий на **GitHub** или **GitVerse**.

### Структура папки `lab_03`:
-  **YAML-файлы.** Все созданные манифесты (`app-deployment.yaml`, `db-deployment.yaml`, `services.yaml` и т.д.).
-  **REPORT.md.** Файл отчета.
-  **img/**. Скриншоты.

### Содержание отчета (`REPORT.md`):
-  **Титульный лист** (ФИО, группа, вариант, описание задачи).
-  **Цель работы**.
-  **Ход выполнения**:
    *   Листинг YAML-файлов (или ссылка на них в репо) с пояснением ключевых строк (image, ports, env, selector).
    *   Скриншот команды `kubectl get pods` (все поды в статусе Running).
    *   Скриншот команды `kubectl get services`.
    *   **Главное.** Скриншот работающего приложения в браузере (интерфейс БД, график, отчет или JSON-ответ).
-  **Выводы**. С какими трудностями столкнулись, как Kubernetes помогает в развертывании аналитики.
-  **Ответы на контрольные вопросы**.

---

## 8. Контрольные вопросы
1.  В чем различие между **Pod**, **Deployment** и **Service**? Зачем нам нужны все три абстракции?
2.  Для чего используется механизм **Labels** и **Selectors** в Kubernetes?
3.  Какие типы **Service** вы знаете (ClusterIP, NodePort, LoadBalancer)? В чем их отличие?
4.  Что произойдет с данными в базе данных внутри пода, если удалить Deployment, не используя Persistent Volumes?
5.  Как посмотреть логи конкретного пода для отладки ошибки запуска?
```